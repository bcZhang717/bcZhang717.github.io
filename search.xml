<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>MySQL 三大日志与两阶段提交</title>
      <link href="/2025/08/25/MySQL/MySQL%20%E4%B8%89%E5%A4%A7%E6%97%A5%E5%BF%97/"/>
      <url>/2025/08/25/MySQL/MySQL%20%E4%B8%89%E5%A4%A7%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>MySQL 的三大日志：undo log、redo log、binlog</p><h1 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h1><h2 id="undo-log-保证事务的原子性"><a href="#undo-log-保证事务的原子性" class="headerlink" title="undo log 保证事务的原子性"></a>undo log 保证事务的原子性</h2><p>执行一组 SQL 语句，要么全部成功，要么全部失败，失败了需要把前面执行成功的 SQL 语句进行回滚，这就是 MySQL 事务的原子性。此时就出现了一个问题：数据都进行修改了，是怎么进行回滚的？</p><p>这就需要 undo log 了。undo log 中记录了数据的不同版本，每修改一次就记录一次对应的版本，随后把数据不同的版本通过一个回滚指针串联起来，这就是 undo log 版本链。</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250825153432795.png" alt="image-20250825153432631" style="zoom:67%;" /><p>也就是说，只要事务执行过程中出现了数据的修改，MySQL 就会把旧数据记录到 undo log 日志当中。如果事务正常提交，那就什么事没有；如果事务执行出现了异常，那就会读取 undo log 日志找到旧数据的版本进行回滚，<strong>这就是 undo log 保证事务原子性的原理</strong>。</p><h2 id="undo-log-与-MVCC"><a href="#undo-log-与-MVCC" class="headerlink" title="undo log 与 MVCC"></a>undo log 与 MVCC</h2><p><strong>undo log 的第二个作用就是配合 readview 与表中的隐藏字段实现 MVCC。</strong></p><p>简单来说，MVCC 执行普通的 select 语句时，会去对比事务的 id 和 readview 来判断数据版本是否对当前的事务可见。如果不可见，就继续沿着 undo log 版本链去查找当前事务可见的数据版本。</p><h1 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h1><h2 id="buffer-pool"><a href="#buffer-pool" class="headerlink" title="buffer pool"></a>buffer pool</h2><p>MySQL 中的数据是存储在磁盘当中的，但是每次都从磁盘读取数据就会很慢，因此 MySQL 设计了一个 buffer pool 缓冲池。MySQL 存数据是以页为单位的，一页的大小是 16 KB，每查询一次数据就会从磁盘把这一页的数据都加载出来，然后放到 buffer pool 当中。</p><h2 id="程序的空间局部性"><a href="#程序的空间局部性" class="headerlink" title="程序的空间局部性"></a>程序的空间局部性</h2><p>为什么每次查询一条数据都会把一整页加载到 buffer pool 当中，而不是单独的这一条数据？</p><p>这就涉及到了程序的空间局部性原理：一个内存地址被访问，这就意味着它附近的内存地址也有可能会被访问，这就好比你刷抖音，当前的视频被访问，那么下一个视频会有极其大的概率也会被访问，这就是一种翻页。</p><p>而 MySQL 一次性把一整页的数据都加载到 buffer pool 当中，那么对于连续存储的数据来说，命中率就会非常高，比如数组。后续再次查找数据的时候就会优先从 buffer pool 中去读取，不存在了再去磁盘当中读取。相应地，写入数据也是先写入 buffer pool，但是不会直接刷入数据到磁盘，而是先将修改的页标记为脏页，再由后台线程在某个时间把脏页刷入到磁盘。</p><h2 id="redo-log-的必要性"><a href="#redo-log-的必要性" class="headerlink" title="redo log 的必要性"></a>redo log 的必要性</h2><p>如果在 buffer pool 还没有刷入脏页到磁盘中的时候，MySQL 宕机了，不就出现了数据丢失，该怎么避免？</p><p>此时 redo log 的作用就体现出来了。MySQL 会把某个磁盘页修改的数据记录在 redo log 中，事务提交之后就刷盘 redo log。如果 buffer pool 中的数据未刷盘就宕机了，那么就可以读取 redo log 来恢复数据，<strong>这也就是 redo log 能够保证事务持久性的原因</strong>，能够让 MySQL 做到崩溃后的数据恢复。</p><h2 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h2><p><strong>为什么不直接刷盘 buffer pool，而是刷盘 redo log？</strong></p><p>因为 buffer pool 刷盘是随机 IO，刷盘的时候需要找到某个磁盘页，然后修改，然后再去找另外一个磁盘页，再修改。本来磁盘操作就慢，随机 IO 的话就更慢了。</p><p>但是 redo log 只记录在哪个磁盘位置做了怎样的修改，刷盘时只需要往 redo log 日志文件后追加就行了，这就是顺序 IO，不需要找这个磁盘页找那个磁盘页，磁盘的磁头只需要沿着一个方向移动就行了。</p><p>这也就是为什么 redo log 里面要记录数据页的物理修改，而不是直接记录数据。所以只要 redo log 一刷盘，即便 MySQL 崩溃了也能够恢复数据，事务的持久性也能够得到保证。</p><h2 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h2><p><strong>如果 redo log 还没来得及刷盘，MySQL 就宕机了，会丢失数据吗？</strong></p><p>我们需要先了解一下 redo log 的刷盘机制，再来解答这个问题。</p><p>redo log 其实也不是直接写入磁盘的，redo log 有自己的缓存，叫 redo log buffer。redo log 会先写入到 redo log buffer，然后统一把 redo log buffer 中的数据刷入到磁盘中。</p><p>MySQL 中有一个参数 <code>innodb_flush_log_at_trx_commit</code> ，可以控制 redo log 的刷盘时间。</p><p>如果值为 0，事务提交时会把 redo log 的数据放入 redo log buffer，并不会刷入磁盘。</p><p>如果值为 1，事务提交时会把 redo log 的数据刷入磁盘，刷盘完成后才会告诉客户端事务执行成功了。这也就保证了事务只要完成，即便 MySQL 崩溃了数据也不会丢失。所以一般情况下，把这个参数设置为 1，那事务提交 redo log 就能刷盘，事务的持久性也能够得到保证，1 也是这个参数的默认值。</p><p>如果值为 2，事务提交时会把 redo log 的数据写入操作系统的文件缓存中，也就是 page cache。操作系统本身对文件也是有缓存的，数据写入 page cache        后，操作系统就会在某个时间把数据写入磁盘，只要操作系统不崩溃，那就能保证持久性。</p><h2 id="问题三"><a href="#问题三" class="headerlink" title="问题三"></a>问题三</h2><p><strong>现在需要做数据库的备份用于备份恢复，或者需要搭建主从架构，完成主从复制，那么 redo log 能胜任这些工作吗？</strong></p><p>这是不行的。redo log 是一种环形日志，其空间大小是固定的。全部写满了就会从头再开始写，边写边覆盖前面的数据。因此它只能记录事务提交后没有被刷盘的数据，已经刷盘的会从 redo log 中擦除掉。</p><p>redo log 是事务级的数据记录，不是数据库级的。它只能做一些因为断电或者数据库故障导致 buffer pool 中的数据未刷盘的数据恢复，不能做数据库全量数据恢复。</p><p>如果需要进行数据库的数据恢复，则需要使用到 binlog 日志文件。</p><h1 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h1><p>只要对 MySQL 做了变更，无论是数据还是表结构的增删改，都会记录一个二进制日志 binlog。</p><p>redo log 是物理日志，记录的内容是 “在某个数据页上做了什么修改”。而 binlog 是逻辑日志，记录的内容就类似于 SQL 语句本身，所以 binlog 非常适合做备份恢复和主从同步。</p><blockquote><p>删库跑路时也最好把 binlog 一起顺手删了，这是非常可刑的。</p></blockquote><p>相比于 redo log，binlog 也有对应的 binlog cache。事务执行过程中，会先把 binlog 日志写到 binlog cache；事务提交的时候，就会把 binlog cache 刷到磁盘中。</p><h1 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h1><p><strong>事务提交后，redo log 和 binlog 都要刷盘，但是如果一个刷盘成功了，一个失败了，两份日志就不一致了，这种情况该怎么办？</strong></p><p>为了解决两份日志之间的一致性问题，MySQL 将 redo log 的写入拆成了两个步骤：<code>prepare</code> 和 <code>commit</code> ，这就是两阶段提交。</p><p>整个执行流程如下：</p><ul><li>开启事务</li><li>更新数据 </li><li>写入 redo log，此时 redo log 是 <code>prepare</code> 阶段</li><li>提交事务，写入 binlog，并将 redolog 设置为 <code>commit</code> 阶段</li></ul><p><strong>1、如果写入 redo log 时出现了异常，该怎么解决？</strong></p><p>此时 redo 处于 <code>prepare</code> 阶段，binlog 中没有数据，直接回滚事务即可。</p><p><strong>2、 如果写入 binlog 时出现了异常，该怎么解决？</strong></p><p>此时 binlog 已经写入，但 redo 还没有进入 <code>commit</code> 阶段，此时就需要对比 redo log <code>prepare</code> 阶段的数据与 binlog 是否一致，一致就提交事务，不一致就回滚事务。</p><p><strong>3、怎么比较 redo log 与 binlog 的数据是否一致？</strong></p><p>redo log 与 binlog 中存在一个共同的字段 <code>XID</code> 。因此崩溃恢复的时候，扫描 redo log，如果发现有 <code>prepare</code> 的 redolog，则利用它的 <code>XID</code> 去 binlog 查询，如果找到对应的数据，则说明数据都保存了，事务可以提交，反之事务回滚。</p><p>由此看来，两阶段提交最终还是要看 binlog 日志。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 日志 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 中的 MVCC</title>
      <link href="/2025/08/25/MySQL/MySQL%20%E4%B8%AD%E7%9A%84%20MVCC/"/>
      <url>/2025/08/25/MySQL/MySQL%20%E4%B8%AD%E7%9A%84%20MVCC/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="什么是-MVCC？"><a href="#什么是-MVCC？" class="headerlink" title="什么是 MVCC？"></a>什么是 MVCC？</h1><p><strong>MVCC：Multi-Version Concurrency Control，多版本并发控制</strong>。MVCC 是一种在数据库管理系统中用来提高并发性能的机制。它主要用于在不加锁或减少加锁的情况下，实现事务的隔离性，从而允许多个事务并发读写数据而不会相互阻塞。</p><h1 id="MVCC-的核心机制"><a href="#MVCC-的核心机制" class="headerlink" title="MVCC 的核心机制"></a>MVCC 的核心机制</h1><h2 id="场景引入"><a href="#场景引入" class="headerlink" title="场景引入"></a>场景引入</h2><p>一张数据库表里面存了很多数据，现在有很多并发事务来访问或者修改数据。在并发事务情况下会出现脏读、不可重复读、幻读问题。</p><p>想要解决脏读，就需要读已提交的隔离级别，也就是说要想办法保证一个事务只能读到其他事务已提交的数据；其他事务没提交的数据，不应该被读取到。</p><p>想要解决不可重复读，就需要可重复读隔离级别，也就是说一个事务第一次读取之后，后面每次读到的数据都应该和第一次一样。即便后面有其他事务新提交了数据也不应该读取到。 </p><h2 id="MVCC-的工作机制"><a href="#MVCC-的工作机制" class="headerlink" title="MVCC 的工作机制"></a>MVCC 的工作机制</h2><p>要想实现上述的需求，就需要用到 <strong>MVCC</strong> 了。</p><p>MVCC 维护了一份数据的多个版本，每个事务修改一次，就生成一个对应的版本，让不同的事务去读不同的版本。</p><p>在读已提交的隔离级别下，让事务去读取已经提交的数据版本，这样就能避免脏读；在不可重复读的隔离级别下，让事务每次都读取同一个版本的数据，这样每次读到的就都一样了，就能避免可重复读的问题。 </p><h3 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h3><p>把修改的数据版本记录到 undo log 日志中，然后给表增加一个隐藏字段：回滚指针。</p><p>让回滚指针指向 undo log 日志，使用回滚指针将历史版本串联为一个链表。这样的话，想读哪个历史版本，沿着链表 一直找就可以了。</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250825211816620.png" alt="image-20250825211816445" style="zoom:67%;" /><p>此时就引出了一个问题：<strong>一个事务来查数据，怎么知道我要查哪个版本的数据呢?</strong></p><p>解决方案就是给每个事务分配一个事务 id，事务 id <strong>自增分配</strong>。通过对比事务 id 的大小，就能知道哪个事务创建的早，哪个事务创建的晚。创建比较晚的事务修改的数据不让创建早的事务看到就行了。</p><p>所以我们需要给表再增加一个隐藏字段：修改数据的事务 id。谁修改了它，就把对应的事务 id 记录下来。</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250825153432795.png" alt="image-20250825153432631" style="zoom:67%;" /><h3 id="readview"><a href="#readview" class="headerlink" title="readview"></a>readview</h3><p>除了 undo log 日志外，还需要一个东西：readview。readview 中存在 4 个重要的字段：</p><ol><li><code>creator_trx_id</code> ：创建当前 readview 的事务 id。</li><li><code>m_ids</code> ：创建 readview 时，当前数据库中存在但未提交的所有事务 id 列表。</li><li><code>min_trx_id</code> ：事务 id 列表中最小的事务 id。</li><li><code>max_trx_id</code> ：创建 readview 时，应该分配的下一个事务的 id。</li></ol><p>这些字段的作用都体现在下图中：</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250825213803769.png" alt="image-20250825213803676" style="zoom:75%;" /><p>readview 的本质就是描绘了一个创建当前事务时的事务 id 数轴。通过对比数据版本的 <code>trx_id</code> 在数轴的哪个位置就能知道这个数据版本是否对当前事务是可见的。</p><p>主要有以下的几种情况：</p><p><strong>情况一：当前数据的 <code>trx_id</code> 值小于 readview 中的 <code>min_trx_id</code> 值</strong></p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250825214529618.png" alt="image-20250825214529523" style="zoom:75%;" /><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250825214911438.png" alt="image-20250825214911351" style="zoom:75%;" /><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250825214831577.png" alt="image-20250825214831507" style="zoom:75%;" />]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> MVCC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何保证缓存与数据库的一致性</title>
      <link href="/2025/08/25/Redis/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/"/>
      <url>/2025/08/25/Redis/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>想要解决缓存与数据库的一致性问题，需要先了解常见的缓存更新策略。</p><h1 id="常见的缓存更新策略"><a href="#常见的缓存更新策略" class="headerlink" title="常见的缓存更新策略"></a>常见的缓存更新策略</h1><h2 id="旁路缓存"><a href="#旁路缓存" class="headerlink" title="旁路缓存"></a>旁路缓存</h2><p>旁路缓存就是 Cache Aside，也是<strong>我们平时业务中经常使用的一种方式</strong>。</p><p>旁路缓存读取数据的基本流程是：先从 Redis 缓存中读取数据，数据存在则直接返回，数据不存在则需要数据库中去读取，然后再写入缓存。</p><p>旁路缓存写入就比较麻烦了：先写入缓存还是先写数据库、写入缓存还是删除缓存、怎么保证缓存与数据库的一致性 ……，这个有点麻烦，我们后续再说。</p><p>总结起来，旁路缓存这种方式的特点就是业务代码既要操作数据库又要操作缓存，以数据库的数据为主，缓存只是暂时存储数据而已。这就是我们经常使用的旁路缓存 Cache Aside。</p><h2 id="读穿写穿"><a href="#读穿写穿" class="headerlink" title="读穿写穿"></a>读穿写穿</h2><p>读穿 Read Through、写穿 Write Through，这是第二种常见的缓存更新策略。它的设计思想是：<strong>不直接操作数据库，只操作缓存，让缓存自身去操作数据库</strong>。 </p><p>读穿的意思是，每次都从缓存中进行读取。如果缓存中存在，则直接返回；如果缓存中不存在数据，则让 <strong>缓存自身</strong> 去数据库中进行查询，然后写入到缓存当中，返回数据。</p><p>写穿的意思是，每次写入数据，直接写入到缓存当中，后续 <strong>缓存自身</strong> 再写入数据到数据库当中。</p><p>总结起来，读穿写穿就是让我们直接操作缓存，只与缓存进行交互，读写数据库的操作交由缓存中间件自身完成。</p><h2 id="写回"><a href="#写回" class="headerlink" title="写回"></a>写回</h2><p>第三种缓存更新策略是写回 Write Back。写回与读穿写穿的思路是一致的，都是直接操作缓存，读写数据库的操作交由缓存中间件自身完成，但是区别是：<strong>写回是异步的写入数据到数据库</strong>。</p><p>也就是说，写回操作只写入数据到缓存，然后让后台线程异步的把缓存的更新写入数据库。这种非常适合写多读少的场景，但是因为是异步地写数据库，所以如果突然宕机, 会有数据丢失的可能。</p><h2 id="思想的应用"><a href="#思想的应用" class="headerlink" title="思想的应用"></a>思想的应用</h2><p>无论是读穿写穿，还是写回，目前做业务的缓存，像 Redis 或者 Memcached， 又或者大厂自研的缓存中间件都没提供这种缓存自身和数据库交互的功能，但是这种思想其实大量的应用到了操作系统和一些中间件的底层设计。</p><p>比如 MySQL 的 Buffer Pool。Buffer Pool 就是 MySQL 在内存中的 一个缓冲池。MySQL 插入数据都是先写入 Buffer Pool，然后在某个时间异步的刷到磁盘当中。然后 MySQL 通过 redolog 来避免数据丢失。</p><p>再比如操作系统的内核缓冲区 Page Cache，其本质也是一个缓存。也是先把数据写入到 Page Cache，然后操作系统在某个时间把数据刷入到磁盘当中。</p><p>其实一些典型的应用场景也使用了这种思想。比如 IDEA 编辑器、画图的软件或者写简历的在线网站，你不去点保存，它也会在某个时间自动地保存数据到磁盘或云端当中，这就是写回思想的一种应用。</p><h1 id="怎么保存缓存和数据库的数据一致性？"><a href="#怎么保存缓存和数据库的数据一致性？" class="headerlink" title="怎么保存缓存和数据库的数据一致性？"></a>怎么保存缓存和数据库的数据一致性？</h1><p>现在我们回头再来看最常用的旁路缓存的写入策略，看看这种更新策略是如何保存缓存和数据库的数据一致性。</p><h2 id="先更新缓存，再更新数据库"><a href="#先更新缓存，再更新数据库" class="headerlink" title="先更新缓存，再更新数据库"></a>先更新缓存，再更新数据库</h2><p>假设有如下的场景：</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250824204455930.png" alt="image-20250824204455742" style="zoom:60%;" /><p>这样就会出现缓存和数据库的不一致性。</p><h2 id="先更新数据库，再更新缓存"><a href="#先更新数据库，再更新缓存" class="headerlink" title="先更新数据库，再更新缓存"></a>先更新数据库，再更新缓存</h2><p>那我们反过来换一个思路：先更新数据库，再更新缓存。假设存在如下的场景：</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250824204903839.png" alt="image-20250824204903751" style="zoom:60%;" /><p>此时又出现了缓存和数据库的不一致性。</p><p>一起来看前两种方案，出现缓存和数据库的不一致性的原因主要是：缓存的更新与数据库的更新不是一个原子性的操作，在并发环境下就可能会出现不一致的问题。</p><p>那是不是只要保证缓存的更新与数据库的更新是一个原子性操作就能保证缓存和数据库的一致性？</p><p>此时我们会想到：<strong>分布式锁</strong> 。只要保证拿到锁的线程才能更新缓存，更新数据库，这不就保证原子性操作了吗，就能保证缓存和数据库的一致性了吗？</p><p>然而事实真是如此吗？</p><p>首先我们来分析，如果加了分布式锁，就不能并发写了，写操作一旦过多，还会导致性能问题。其次分布式锁本身也存在一些难以解决的问题，因此 <strong>使用分布式锁的方式不能够保证缓存和数据库的一致性</strong>。</p><p><strong>那选择使用分布式读写锁，利用其读读不互斥，读写互斥的特性？</strong></p><p>其实这种方案还不如第一种分布式锁的方案。首先读写锁是读写互斥的，读的时候不允许写；写的时候不允许读，这样就会导致如下的问题：</p><ul><li><p>在高并发场景下，大量的请求进来都在读取这个 key，此时你完全不能进行写操作；</p></li><li><p>如果此时你正在执行一个比较耗时的写操作，突然涌入大量的读取操作，那么这些大量的请求就只能阻塞等待写操作完成后在执行</p></li></ul><p>再退一步来说，我们为什么选择使用缓存？首先想到的就是 **Redis 是基于内存操作，读写速率非常快！**但现在我们为了数据的一致性而选择了加锁这种比较重的资源，反而影响了 Redis 的读写性能，是不是本末倒置了，忘记了我们使用缓存的初衷？</p><p>综合来说，无论是先更新缓存还是先更新数据库，这两种方案是都不能保证缓存和数据库的一致性的。</p><h2 id="先删除缓存，再更新数据库"><a href="#先删除缓存，再更新数据库" class="headerlink" title="先删除缓存，再更新数据库"></a>先删除缓存，再更新数据库</h2><p>既然更新缓存行不通，那我们就再换个思路：删除缓存。这里选择删除缓存是因为以下两点原因：</p><ul><li>删除缓存操作相比于更新缓存代价更低，操作更便捷</li><li>如果更新了缓存没有请求去访问，然后数据库又进行了更新，那就意味着还需要重新更新缓存，那之前更新的缓存不就是无效的，没有意义的？</li></ul><p>所以对于缓存来说，最好的方案就是：需要查询的时候再去更新；更新数据库的时候直接删除缓存即可。</p><p>现在确定了策略就是先删除缓存，再更新数据库，此时还会不会出现缓存和数据库的不一致问题呢？</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250824211538686.png" alt="image-20250824211538503" style="zoom:60%;" /><p>可以看到，此时又又又出现了缓存和数据库的不一致性。</p><h2 id="延迟双删"><a href="#延迟双删" class="headerlink" title="延迟双删"></a>延迟双删</h2><p>既然有其他的请求会更新缓存，导致数据的不一致，那么可不可以把最后一次更新缓存的数据给删除了，这样不就能保证数据的一致性了吗？</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250824212102543.png" alt="image-20250824212102433" style="zoom:60%;" /><p>具体的操作就是：先删除缓存，再更新数据库，然后让线程等待一会再去执行删除最后更新的缓存。这里线程等待的原因就是留出时间给其他的线程进行读取数据库数据并写入缓存的操作，然后再把写入缓存的数据一删，这样就保证了缓存与数据库的一致性，这多是一件美事！🤪🤪🤪</p><p>然而事实就是这样吗？这里还存在一个不确定性的因素：延迟双删，那么线程应该等待多久呢，到底需要多长时间其他线程能完成进行读取数据库数据并写入缓存的操作呢？</p><p>这不仅需要考虑当时的网络情况，还跟服务器与数据库的负载相关，这个时间是不确定的，没有一个准确的值。因此延迟双删这个方案也是不可行的。</p><h2 id="先更新数据库，再删除缓存"><a href="#先更新数据库，再删除缓存" class="headerlink" title="先更新数据库，再删除缓存"></a>先更新数据库，再删除缓存</h2><p>那我思路再变，先更新数据库，再删除缓存。</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250824213234931.png" alt="image-20250824213234830" style="zoom:60%;" /><p>但是此时又又又又又出现了缓存与数据库数据的不一致问题！！！</p><p>不过这种方案出现缓存与数据库数据的不一致性是概率很低的。需要同时满足以下两点原因才有可能出现不一致性：</p><ul><li>Key 正好过期且数据库也需要更新数据</li><li><strong>请求 1 写缓存的速度</strong> 要小于 <strong>请求 2 更新数据库数据加删除缓存的概率</strong> ，这是概率极其低的</li></ul><p>由此来说：<strong>先更新数据库，再删除缓存，这种方案在绝大多数情况下是可行的</strong>。</p><h3 id="如果数据库更新成功，缓存删除失败了呢？"><a href="#如果数据库更新成功，缓存删除失败了呢？" class="headerlink" title="如果数据库更新成功，缓存删除失败了呢？"></a>如果数据库更新成功，缓存删除失败了呢？</h3><p>这种情况下就又又又出现了缓存与数据库数据的不一致问题，所以我们的解决思路应该是：<strong>必须要确保删除缓存的操作要成功执行</strong>。</p><p>为了保证成功执行，我们主要有两个方案：使用 MQ 或 监听 binlog 日志。</p><h3 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h3><p>把删除缓存的操作放入到 MQ 中去异步的执行，如果删除失败了，就可以利用 MQ 的重试机制进行重试，这样就能够有效保证删除缓存操作的执行。</p><h3 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h3><p>数据库更新数据的时候会产生一个 binlog 日志，我们也可以通过监听 MySQL 的 binlog 日志，如果日志中出现了数据，就代表 MySQL 进行了更新操作。我们再执行相应的删除缓存操作，删除失败再进行重试即可。</p><p>所以综合看下来，最理想的方案就是：<strong>先更新数据库，然后通过 MQ 或 监听 binlog 的方式异步删除缓存，如果删除缓存失败就进行重试。</strong></p><h1 id="主从模式下的不一致性问题"><a href="#主从模式下的不一致性问题" class="headerlink" title="主从模式下的不一致性问题"></a>主从模式下的不一致性问题</h1><p>实际上企业或公司的数据库都是主从模式读写分离的，主库负责写操作，从库负责读取，主库更新数据之后再同步给从库。</p><p>此时就会出现一个问题：主库执行数据更新操作并删除缓存之后，还没来得及同步给从库，此时又来了请求读取该数据，从库负责读，那么势必会读取从库的旧数据，然后写入缓存，这就又造成了缓存和数据库数据的不一致性，当然这种概率也是非常非常非常低的。</p><p>而想要解决这个问题，那就需要在主库更新数据后的一段时间内让后续的请求强制读取主库。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>此时到这里我们就应该明白：<strong>想要完全的保证缓存与数据库数据的一致性，那是不可能的</strong>。</p><p>我们最常用的方式就是：<strong>先更新数据库，然后通过 MQ 或 监听 binlog 的方式异步删除缓存，如果删除缓存失败就进行重试。</strong> 这也只是尽可能地保证缓存和数据库的在绝大多数场景下的一致性，同时我们也需要设置好数据的过期时间，即使某些极端场景下出现了不一致性问题，那也能够及时保证脏数据的过期失效。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 中 SQL 的执行流程与编写顺序</title>
      <link href="/2025/08/24/MySQL/MySQL%20%E4%B8%AD%20SQL%20%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E4%B8%8E%E7%BC%96%E5%86%99%E9%A1%BA%E5%BA%8F/"/>
      <url>/2025/08/24/MySQL/MySQL%20%E4%B8%AD%20SQL%20%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E4%B8%8E%E7%BC%96%E5%86%99%E9%A1%BA%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="一条-SQL-语句是如何执行的？"><a href="#一条-SQL-语句是如何执行的？" class="headerlink" title="一条 SQL 语句是如何执行的？"></a>一条 SQL 语句是如何执行的？</h1><p>先说结论：一条 SQL 语句的执行需要经历：<strong>连接器</strong>、<strong>缓存层</strong>、<strong>解析器</strong>、<strong>优化器</strong>、<strong>执行器</strong> 五个步骤。下面以一个买鸡蛋的例子来进行说明 SQL 的具体执行流程。</p><h2 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h2><p>首先买鸡蛋的第一步就是：让妈妈先找到我，给我一个去买鸡蛋的指令。</p><p>相应的，我们需要执行 SQL，第一步就是先连接上数据库，通过网络把 SQL 语句传输过去，然后数据库才能帮我执行 SQL 语句。</p><p>这就是连接器的工作，连接器就是客户端与数据库之间进行连接，主要步骤是：</p><ul><li>先进行 TCP 的三次握手与数据库建立连接</li><li>校验客户端的用户名与密码是否正确，不正确则报错</li><li>做权限校验，判断当前用户是否有权限访问数据库</li></ul><h2 id="缓存层"><a href="#缓存层" class="headerlink" title="缓存层"></a>缓存层</h2><p>现在我收到了买鸡蛋的指令，下一步就直接出门去买吗？当然不是！我们应该先看看家里还有没有剩下的鸡蛋，有就直接用呗，没有了才去买。</p><p>相应的，连接上数据库之后，需要先查询缓存。以传输的 SQL 语句作为 key，以查询的结果作为 value，如果缓存中存在 value，那就说明之前执行过一样的SQL 语句，那我就直接拿来用呗，不用重复执行了。</p><p><strong>为什么 MySQL 会有缓存存在？</strong></p><p>程序有时间局部性，当某一段代码或者某一段指令被执行时，很有可能这段代码还会被重复执行。或者说某一段内存位置被访问时，很有可能这个内存位置还会被再次访问，这是因为代码中会存在大量的循环、递归等操作，导致某段指令被重复执行，这就是时间局部性的原理。所以一条被执行过的 SQL，在未来很有可能被再次执行，这就是为啥要对 SQL 做缓存。</p><p><strong>为什么 MySQL 8.0 又去掉了缓存？</strong></p><p>因为一旦表数据一变化，那 SQL 执行的结果就有可能不一样，所以表数据变化时就应该删除缓存。而实际上很多 SQL 在执行的时候，where 条件是会不断变化的，这就导致了 SQL 看着都差不多，但是条件稍微不一样它就走不了缓存，所以查询缓存的命中率并不高，MySQL 在 8.0 就把查询缓存去掉了。</p><h2 id="解析层"><a href="#解析层" class="headerlink" title="解析层"></a>解析层</h2><p>回到买鸡蛋的问题，现在家里确定没有鸡蛋了，要去买。但是还需要思考一个问题：我想要吃鸡蛋吗？我不想吃就要告诉我妈妈不买了，我想吃就要考虑买多少个。</p><p>相应的，SQL 语句下一步到达解析器。解析器就是判断 SQL 语句的具体想法，分为三步：</p><ul><li><p>词法分析。拆分 SQL 语句的关键词，比如 <code>select</code> 、<code>from</code> 、<code>where</code> 、<code>order by</code> 等。</p></li><li><p>语法分析。判断 SQL 语句的编写语法是否是正确的，不正确就报错；正确的话就构建语法解析树，方便后续获得表名、字段名。</p></li><li><p>检查表，判断字段是否存在。</p></li></ul><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>现在我确定要买鸡蛋，我确实想吃鸡蛋，我也确定了要买 20 个鸡蛋。接下来就需要计划怎么买了：是去超市买还是去菜市场买？是骑车去买还是坐公交车去买？</p><p>相应的，SQL 语句接下来就到了优化器。优化器的职责就是给 SQL 制定一个计划：怎么执行 SQL 是最快的，是走索引还是全表扫描，走索引的话走哪个索引？</p><h2 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h2><p>现在我的计划完成了，然后就是执行计划：骑车去菜市场买鸡蛋。所以我就还需要跟卖鸡蛋的老板交流，付钱。</p><p>相应的，SQL 语句最后抵达执行器。执行器的任务就是与存储引擎层进行交互，执行相应的 SQL 语句，然后从存储引擎中拿到结果返回。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一条 SQL 语句的执行顺序可以以下图作为参考：<br><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250824171942925.png" alt="img" style="zoom:57%;" /></p><h1 id="SQL-语句顺序"><a href="#SQL-语句顺序" class="headerlink" title="SQL 语句顺序"></a>SQL 语句顺序</h1><h2 id="SQL-编写顺序"><a href="#SQL-编写顺序" class="headerlink" title="SQL 编写顺序"></a>SQL 编写顺序</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> 字段名</span><br><span class="line"><span class="keyword">from</span> 表名</span><br><span class="line"><span class="keyword">join</span> 多表查询</span><br><span class="line"><span class="keyword">where</span> 条件</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> 分组</span><br><span class="line"><span class="keyword">having</span> 分组后过滤</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> 查询结果排序</span><br><span class="line">limit 查询结果分页</span><br></pre></td></tr></table></figure><h2 id="SQL-执行顺序"><a href="#SQL-执行顺序" class="headerlink" title="SQL 执行顺序"></a>SQL 执行顺序</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> 表名</span><br><span class="line"><span class="keyword">join</span> 多表查询</span><br><span class="line"><span class="keyword">where</span> 查询条件</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> 分组</span><br><span class="line"><span class="keyword">having</span> 分组后过滤</span><br><span class="line"><span class="keyword">select</span> 返回字段名</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> 查询结果排序</span><br><span class="line">limit 查询结果分页</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 持久化机制</title>
      <link href="/2025/08/24/Redis/Redis%20%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/"/>
      <url>/2025/08/24/Redis/Redis%20%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Redis-的持久化机制"><a href="#Redis-的持久化机制" class="headerlink" title="Redis 的持久化机制"></a>Redis 的持久化机制</h1><p>讨论 Redis 持久化机制之前，我们应该先想一下 MySQL 是怎么做的数据持久化：先把数据保存到日志当中，再执行 SQL 语句，这样就保证了 MySQL 突然宕机后的数据恢复能力，直接读取日志即可恢复。</p><p>那么对于 Redis 来讲，也是一样的操作：<strong>写日志</strong>。Redis 中提供了两种持久化策略，一种是 RDB 持久化、一种是 AOF 持久化。</p><h2 id="RDB-持久化"><a href="#RDB-持久化" class="headerlink" title="RDB 持久化"></a>RDB 持久化</h2><p>RDB 持久化本质上保存的是 <strong>数据快照</strong>，它把 Redis 中保存的数据以二进制的形式写入到一个 RDB 文件当中，该文件默认是 <code>dump.rdb</code> 。</p><p>需要注意的是 RDB 持久化保存的是当前时间下 Redis 内的二进制全量数据，这就会引发一个问题：RDB 持久化每次都保存 Redis 的全量数据，那这个过程是不是很慢？</p><p>答案是肯定的。而 Redis 提供了两个命令来实现 RDB 的持久化：<code>save</code> 与 <code>bgsave</code>。</p><p>先来看 <code>save</code> ：save 是在主线程去保存 RDB 数据快照，这样势必就会带来一个问题：阻塞主进程的读写命令执行，所以这种方式是我们所不推荐的。</p><p>再来看 <code>bgsave</code> ：bgsave 表示开启一个子进程来执行 RDB 持久化，这样就不会阻止主进程读写的命令了，这是 RDB 持久化的默认选择。实际上这种方式的持久化机制使用了一种 “写时复制” 的思想，在 JDK 中的体现就是 <code>CopyOnWriteArraylist</code> 类。</p><p>但是即使是使用 <code>bgsave</code> 开启一个子进程来执行 RDB 持久化，不还是存在 RDB 持久化过程缓慢的缺点吗？</p><p>是的，这是不可避免的。而由于 RDB 过程比较慢，我们最好手动设置一个持久化频率来避免频繁地进行 RDB 持久化。通过配置文件可以配置在 x 秒内有 y 个 key 发生变化就进行 RDB 持久化操作，或者直接固定好时间，比如 5 分钟执行一次持久化。但是如果在这个过程中 Redis 出现了宕机，那么就会相应的丢失规定时间内的数据。</p><p>这就是 RDB 持久化的缺点：<strong>过程缓慢且容易丢失数据</strong>。但 RDB 持久化也是具有一定的优势的：RDB 内存储的是二进制的全量数据，Redis 故障恢复后直接读取数据写入内存就能恢复，也就是说，<strong>RDB 持久化方式下 Redis 的故障恢复能力很快</strong>。</p><p>在这里就又引出了一个问题：<strong>子进程保存 RDB 快照时，主进程还能写入或者修改数据吗？</strong></p><p>答案是可以的。上面我们提到 RDB 的 <code>bgsave</code> 方式是基于 “写时复制” 的思想，这样就保证了 <strong>RDB 持久化的过程中也是可以在主线程进行数据的写入或修改操作的</strong>。</p><p>主进程 fork 子进程后，并不是把所有数据都复制一份给子进程，而是使主进程与子进程共享相同的内存页面。也就是说仅仅复制了页表，使二者指向同一个物理地址，这样可以加快 fork 的速度，减少性能消耗。</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250824151337254.png" alt="img" style="zoom:67%;" /><p>如果此时收到了写命令，那么主进程会对数据所在的页进行复制一份，<strong>在副本上进行修改</strong>，此时子进程还是指向的老的页，数据是没有发生变化的，这就是 <strong>写时复制</strong> 的思想。</p><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250824151424735.png" alt="img" style="zoom:67%;" /><h2 id="AOF-持久化"><a href="#AOF-持久化" class="headerlink" title="AOF 持久化"></a>AOF 持久化</h2><p>RDB 是保存二进制全量数据进行持久化，那我们可不可以试想一下另一种方案：<strong>不保存全部的数据了，只保存写命令的操作。即使 Redis 宕机了，那等 Redis 重启之后再次执行一遍这些写命令，不也是可以恢复数据吗，这就是 AOF 的思想</strong>。</p><p>AOF 持久化机制是什么样的？我们不妨先想想 MySQL 的思路：<strong>先把数据写入到 Buffer Pool 缓冲区，然后在某个时间段异步的刷入到磁盘当中</strong>。所以对于 Redis 的 AOF 来讲，过程是类似的：</p><ul><li>先执行主线程的命令</li><li>然后记录命令到 AOF 缓冲区</li><li>其次写入操作系统的内核缓冲区 Page Cache</li><li>最后在某个时间段内刷入到磁盘当中</li></ul><p>那么在 AOF 中到底什么时间才会把数据刷入磁盘呢，Redis 给我们提供了三种选择：<code>always</code>、<code>no</code>、<code>everysec</code> 。</p><p>先来看 <code>always</code> ：这种方式是通过主线程每次执行完命令就立刻刷入到磁盘当中，该方式能够最大程度的保证数据的不丢失，但是是由主线程来操作的，会对主线程执行命令时的性能造成一定影响。</p><p>再来看 <code>no</code> ：这种方式是说不主动进行刷盘，而是由操作系统自己来决定什么时候把数据刷入磁盘。这种方式虽然缓解了主线程的性能影响，但是其刷盘时机是不确定的，会一定程度上增加数据丢失的风险。 </p><p>最后看 <code>everysec</code> ：该方式是指每次执行完命令后，先把命令写入到缓冲区，然后每隔 1 秒刷一次盘，这是对前面两种方式的一种折中选择。在该方式下，即使丢失数据也只会丢失 1 秒内的数据，既保证了 Redis 执行命令的性能，又不会丢失太多的数据。</p><p>下面我们来看两个问题：</p><p><strong>1、always 一定能够保证不丢失数据吗？</strong></p><p>always 也不能保证数据一定不丢失。因为 Redis 是先执行命令再写入 AOF，如果写入 AOF 这段时间宕机，那么 AOF 就不能保证数据的存在。</p><p><strong>2、为什么 AOF 先执行命令再写入日志，而不是像 MySQL 先写入日志，再执行命令？</strong></p><p><strong>从 MySQL 的角度来看</strong>：MySQL 是关系型数据库，其根本的工作最大程度上就是保证数据不能丢失。其核心是保证事务的 ACID，保证数据的持久性，数据是坚决不能丢的，因此选择先写入日志，再执行命令。</p><p><strong>而对于 Redis 来说</strong>，虽然也是数据库，但往往 Redis 的应用场景是作为缓存存在，也就是说是作为临时存储数据的桥梁，实际数据还是以 MySQL 中的数据为主。而我们用缓存最大的目的不就是 <strong>快</strong> 嘛。所以 Redis 先执行命令再写入日志 (写入 AOF 可以理解为写日志)，完全符合其 <strong>快</strong> 的特点。</p><p>换一个角度再来看：Redis 先执行命令，那么就说明了 Redis 执行的命令是有效的，这样在执行 AOF 的时候就不需要再进行命令合法性的检查了，可以直接写入。</p><p>假设有如下的场景：<code>set key1 1</code>、<code>set key1 2</code>、<code>set key1 3</code> ……、<code>set key1 99999</code> ，对于这样的一串命令，实际上只有最后一次的命令是有效的，前面的命令都是历史值，我们不关心。</p><p>但是 AOF 是会记录所有的写命令的啊，这样一来不就导致了 AOF 文件过大，且 Redis 宕机重启后会执行前面一堆的无效命令？</p><p>针对于上述情况，<strong>AOF 提供了重写机制</strong>。</p><p>AOF 重写会根据现有的 AOF 文件进行重写，意思就是：<strong>新建一个新的 AOF 文件用于写入符合要求的有效的命令，形成一个与原 AOF 文件等效的文件，且体积还比原 AOF 文件小</strong>。AOF 重写是 Redis 开启一个新进程实现的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>RDB 是全量数据快照，保存慢，需要每隔一段时间保存一次且容易丢数据，但是 Redis 重启恢复数据比较快。 </p><p>AOF 仅保存 Redis 的写命令，保存快且不容易丢数据，但是 Redis 重启后恢复数据需要一条条执行命令，这个过程比较慢。</p><h2 id="RDB-与-AOF-混合持久化"><a href="#RDB-与-AOF-混合持久化" class="headerlink" title="RDB 与 AOF 混合持久化"></a>RDB 与 AOF 混合持久化</h2><p><strong>有没有一种方案能够兼顾 RDB 的故障恢复能力且 AOF 的不易丢失数据的特点呢？</strong> </p><p>Redis 4.0 版本提出了 <strong>RDB 与 AOF 混合持久化</strong> 的方案来实现了二者优点的兼顾，其工作原理是：</p><p>1、在执行 AOF 重写的时候，把当前 Redis 中的数据以 RDB 的方式写入  AOF，把写命令以 AOF 的方式写入 AOF。</p><p>2、这样就形成了重写后的 AOF 文件，前半段是 RDB 的二进制文件，后半段是 AOF 记录的 Redis 写命令。</p><p>3、这样就保证了 Redis 故障恢复能力的速度，还降低了数据丢失的风险。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 日志 </tag>
            
            <tag> Redis </tag>
            
            <tag> 持久化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>缓存击穿、缓存穿透、缓存雪崩问题及解决方案</title>
      <link href="/2025/08/24/Redis/%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E3%80%81%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
      <url>/2025/08/24/Redis/%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E3%80%81%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h1><h2 id="什么是缓存击穿？"><a href="#什么是缓存击穿？" class="headerlink" title="什么是缓存击穿？"></a>什么是缓存击穿？</h2><p>缓存击穿指的是某个热点 key 在缓存中突然失效了，导致大量的请求都到达数据库，给数据库带来了不必要的压力。</p><h2 id="缓存击穿的解决方案"><a href="#缓存击穿的解决方案" class="headerlink" title="缓存击穿的解决方案"></a>缓存击穿的解决方案</h2><ul><li>互斥锁&#x2F;分布式锁</li><li>逻辑过期</li><li>互斥锁&#x2F;分布式锁 + 逻辑过期</li><li>定时刷新</li></ul><h3 id="互斥锁-分布式锁"><a href="#互斥锁-分布式锁" class="headerlink" title="互斥锁&#x2F;分布式锁"></a>互斥锁&#x2F;分布式锁</h3><p>互斥锁&#x2F;分布式锁的具体原理就是：利用锁的互斥性，保证多个请求中只有一个请求能够到达数据库并访问数据库进行更新缓存，其它的请求阻塞等待。</p><p>需要做一个双重检测的机制，避免重复查询。其他请求拿到锁之后先判断缓存中是否存在数据，存在数据直接返回即可。</p><p>伪代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">cacheKey</span> <span class="operator">=</span> <span class="string">&quot;hot_key&quot;</span>;</span><br><span class="line"><span class="type">Object</span> <span class="variable">cached</span> <span class="operator">=</span> redis.get(cacheKey);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (cached != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> cached; <span class="comment">// 缓存命中, 直接返回</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 尝试获取分布式锁(比如用 Redis 的 SETNX 或 RedLock)</span></span><br><span class="line"><span class="type">String</span> <span class="variable">lockKey</span> <span class="operator">=</span> <span class="string">&quot;lock:&quot;</span> + cacheKey;</span><br><span class="line"><span class="type">boolean</span> <span class="variable">locked</span> <span class="operator">=</span> redis.setIfAbsent(lockKey, <span class="string">&quot;1&quot;</span>, <span class="number">10</span>, TimeUnit.SECONDS); <span class="comment">// 设置 10 秒超时</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (locked) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 2. 双重检查, 可能其他线程已经重建好缓存了</span></span><br><span class="line">        cached = redis.get(cacheKey);</span><br><span class="line">        <span class="keyword">if</span> (cached != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> cached;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 查数据库</span></span><br><span class="line">        <span class="type">Object</span> <span class="variable">dbData</span> <span class="operator">=</span> queryFromDB(cacheKey);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 写回缓存</span></span><br><span class="line">        redis.set(cacheKey, dbData, <span class="number">3600</span>); <span class="comment">// 设置新的过期时间</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dbData;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// 释放锁</span></span><br><span class="line">        redis.del(lockKey);</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 没抢到锁, 短暂等待后重试, 或者直接返回旧数据/默认值</span></span><br><span class="line">    Thread.sleep(<span class="number">100</span>);</span><br><span class="line">    <span class="keyword">return</span> getFromCacheWithLock(cacheKey); <span class="comment">// 重试, 或者 return 默认值/兜底数据</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种方式数据一致性比较强，但是需要阻塞等待，会对性能造成一定影响。</p><h3 id="逻辑过期"><a href="#逻辑过期" class="headerlink" title="逻辑过期"></a>逻辑过期</h3><p>逻辑过期就是指不设置缓存 key 的过期时间，使其永不过期，由我们在保存缓存数据的时候手动维护一个 <code>expireTime</code> 字段到 Redis 当中。比如保存 JSON 或 Map 的时候显式的指定一个 <code>expireTime</code> 字段，字段中保存当前时间的时间戳 + 手动的过期时间。</p><p>每次获取数据的时候，解析相应的 <code>expireTime</code> 字段，与当前的时间戳进行比较，若保存的时间戳大于当前时间，则表示还没有逻辑过期，否则就已经过期，过期之后可以开启一个新的线程更新缓存或者使用消息队列去更新缓存。</p><p>该方案可能会存在短暂时间的脏数据，但是不需要阻塞请求。</p><h3 id="互斥锁-分布式锁-逻辑过期"><a href="#互斥锁-分布式锁-逻辑过期" class="headerlink" title="互斥锁&#x2F;分布式锁 + 逻辑过期"></a>互斥锁&#x2F;分布式锁 + 逻辑过期</h3><p>实际环境中，都是二者一起去使用来防止缓存击穿的，伪代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CacheService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> StringRedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 逻辑过期时间: 例如 10 分钟</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">LOGICAL_EXPIRE_TIME</span> <span class="operator">=</span> <span class="number">10</span> * <span class="number">60</span> * <span class="number">1000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 缓存 key</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">CACHE_KEY</span> <span class="operator">=</span> <span class="string">&quot;product:123&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getDataWithLogicalExpire</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">jsonStr</span> <span class="operator">=</span> redisTemplate.opsForValue().get(CACHE_KEY);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 缓存为空, 需要重建</span></span><br><span class="line">        <span class="keyword">if</span> (jsonStr == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> rebuildCacheAndReturn();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 解析 JSON 获取 expireTime</span></span><br><span class="line">        <span class="type">JSONObject</span> <span class="variable">jsonObject</span> <span class="operator">=</span> JSON.parseObject(jsonStr);</span><br><span class="line">        <span class="type">Long</span> <span class="variable">expireTime</span> <span class="operator">=</span> jsonObject.getLong(<span class="string">&quot;expireTime&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">data</span> <span class="operator">=</span> jsonObject.getString(<span class="string">&quot;data&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 判断是否逻辑过期</span></span><br><span class="line">        <span class="keyword">if</span> (expireTime &gt; System.currentTimeMillis()) &#123;</span><br><span class="line">            <span class="comment">// 未过期，直接返回数据</span></span><br><span class="line">            <span class="keyword">return</span> data;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 已逻辑过期，触发异步缓存更新（防止击穿）</span></span><br><span class="line">            asyncRefreshCache();</span><br><span class="line">            <span class="comment">// 依然返回旧数据（可容忍短暂脏读）</span></span><br><span class="line">            <span class="keyword">return</span> data;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 异步刷新缓存(可用线程池或消息队列)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">asyncRefreshCache</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 提交到线程池执行, 避免阻塞主线程</span></span><br><span class="line">        ThreadPool.submit(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 获取最新数据</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">freshData</span> <span class="operator">=</span> queryFromDatabase();</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 构造新的 JSON, 设置新的逻辑过期时间</span></span><br><span class="line">                <span class="type">JSONObject</span> <span class="variable">newJson</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JSONObject</span>();</span><br><span class="line">                newJson.put(<span class="string">&quot;data&quot;</span>, freshData);</span><br><span class="line">                newJson.put(<span class="string">&quot;expireTime&quot;</span>, System.currentTimeMillis() + LOGICAL_EXPIRE_TIME);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 更新 Redis 缓存</span></span><br><span class="line">                redisTemplate.opsForValue().set(CACHE_KEY, newJson.toJSONString());</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                <span class="comment">// 记录日志, 避免影响主流程</span></span><br><span class="line">                log.error(<span class="string">&quot;异步刷新缓存失败&quot;</span>, e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 首次缓存为空时, 同步重建并返回</span></span><br><span class="line">    <span class="keyword">private</span> String <span class="title function_">rebuildCacheAndReturn</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 加分布式锁, 防止缓存击穿(多个线程同时重建)</span></span><br><span class="line">        <span class="type">Boolean</span> <span class="variable">locked</span> <span class="operator">=</span> redisTemplate.opsForValue().setIfAbsent(<span class="string">&quot;lock:&quot;</span> + CACHE_KEY, <span class="string">&quot;1&quot;</span>, <span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">        <span class="keyword">if</span> (!locked) &#123;</span><br><span class="line">            <span class="comment">// 未获取到锁, 短暂等待或直接查库(降级)</span></span><br><span class="line">            Thread.sleep(<span class="number">100</span>);</span><br><span class="line">            <span class="keyword">return</span> getDataWithLogicalExpire(); <span class="comment">// 递归重试</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 查询数据库</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">freshData</span> <span class="operator">=</span> queryFromDatabase();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 构建带逻辑过期的 JSON</span></span><br><span class="line">            <span class="type">JSONObject</span> <span class="variable">newJson</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JSONObject</span>();</span><br><span class="line">            newJson.put(<span class="string">&quot;data&quot;</span>, freshData);</span><br><span class="line">            newJson.put(<span class="string">&quot;expireTime&quot;</span>, System.currentTimeMillis() + LOGICAL_EXPIRE_TIME);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 写入 Redis</span></span><br><span class="line">            redisTemplate.opsForValue().set(CACHE_KEY, newJson.toJSONString());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> freshData;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">// 释放锁</span></span><br><span class="line">            redisTemplate.delete(<span class="string">&quot;lock:&quot;</span> + CACHE_KEY);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String <span class="title function_">queryFromDatabase</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 模拟查库</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Data from DB&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="定时刷新"><a href="#定时刷新" class="headerlink" title="定时刷新"></a>定时刷新</h3><p>使用定时任务框架，比如 Spring Scheduler、xxl-job 等，针对每个热点 key 进行记录过期时间，在过期时间之前刷新数据，比如 1 分种过期时间进行数据刷新。</p><h1 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h1><h2 id="什么是缓存穿透？"><a href="#什么是缓存穿透？" class="headerlink" title="什么是缓存穿透？"></a>什么是缓存穿透？</h2><p>缓存穿透指的是数据在缓存和数据库中都不存在，从而导致大量的请求直接访问数据库，造成数据库压力过载，甚至出现宕机。</p><h2 id="缓存穿透解决方案"><a href="#缓存穿透解决方案" class="headerlink" title="缓存穿透解决方案"></a>缓存穿透解决方案</h2><p>缓存穿透的解决可以分为多个步骤。</p><h3 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h3><p>首先对请求参数做好校验，拦截非法的请求。对于一些异常的用户或者异常的 IP 直接进行限流或者设置黑名单禁止访问，可以在网关层中进行拦截。</p><h3 id="第二步"><a href="#第二步" class="headerlink" title="第二步"></a>第二步</h3><p>对于数据库中查不到的数据缓存一个空值进行返回，同时设置一个较短的过期时间，避免后续增加了该数据后反而查不到。</p><h3 id="第三步"><a href="#第三步" class="headerlink" title="第三步"></a>第三步</h3><p>如果恶意用户构造大量不存在的数据疯狂攻击我们，那么缓存空值就力不从心了，可以使用布隆过滤器来实现。写数据库的时候同时写布隆过滤器，后续打来的请求通过布隆过滤器进行判断。</p><p>布隆过滤器就是把数据经过多个 hash 函数进行计算得到多个 hash 值，然后把 hash 值映射到一个 bitmap 中，把对应位置修改为 1。请求来了，就对这些数据用 hash 函数做计算，然后看看这几个 hash 值对应的 bitmap 的那个位置上是不是 1，是 1 说明有，是 0 说明没有。</p><p>但是布隆过滤器是存在一定误判的可能的。且布隆过滤器不支持删除，因为无法确定哪个哈希值是哪个元素设置的。</p><h1 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h1><h2 id="什么是缓存雪崩？"><a href="#什么是缓存雪崩？" class="headerlink" title="什么是缓存雪崩？"></a>什么是缓存雪崩？</h2><p>缓存雪崩指的是在同一时期大量的缓存 key 突然 <strong>同时过期</strong>，导致所有的请求都直接访问数据库，从而导致数据库的流量激增，压力骤增，最终导致宕机。</p><h2 id="缓存雪崩解决方案"><a href="#缓存雪崩解决方案" class="headerlink" title="缓存雪崩解决方案"></a>缓存雪崩解决方案</h2><ul><li>随机过期时间</li><li>缓存永不过期</li><li>缓存预热</li><li>多级缓存</li></ul><h3 id="随机过期时间"><a href="#随机过期时间" class="headerlink" title="随机过期时间"></a>随机过期时间</h3><p>该方案就是在给定一个固定的过期时间之后再随机加上一个随机数，从而避免大量缓存数据的同时过期。</p><p>示例代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Redis 优化分页查询</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> queryRequest 查询参数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 分页结果</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> Page&lt;PictureVO&gt; <span class="title function_">listPictureVOByPageWithCache</span><span class="params">(PictureQueryRequest queryRequest)</span> &#123;</span><br><span class="line">    <span class="comment">// 1. 构建 Redis Key</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">jsonStr</span> <span class="operator">=</span> JSONUtil.toJsonStr(queryRequest);</span><br><span class="line">    <span class="type">String</span> <span class="variable">md5Str</span> <span class="operator">=</span> DigestUtils.md5DigestAsHex(jsonStr.getBytes());</span><br><span class="line">    <span class="keyword">final</span> <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> <span class="string">&quot;picture:listPictureVOByPage:&quot;</span> + md5Str;</span><br><span class="line">    <span class="comment">// 2. 先查询 Redis</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">valueData</span> <span class="operator">=</span> redisTemplate.opsForValue().get(key);</span><br><span class="line">    <span class="keyword">if</span> (StrUtil.isNotBlank(valueData)) &#123;</span><br><span class="line">        <span class="comment">// 缓存中存在数据, 直接返回(避免泛型擦除)</span></span><br><span class="line">        <span class="keyword">return</span> JSONUtil.toBean(valueData, <span class="keyword">new</span> <span class="title class_">TypeReference</span>&lt;Page&lt;PictureVO&gt;&gt;() &#123;</span><br><span class="line">        &#125;, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 3. 不存在, 查询数据库</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">current</span> <span class="operator">=</span> queryRequest.getCurrent();</span><br><span class="line">    <span class="type">int</span> <span class="variable">pageSize</span> <span class="operator">=</span> queryRequest.getPageSize();</span><br><span class="line">    Page&lt;Picture&gt; picturePage = <span class="built_in">this</span>.page(<span class="keyword">new</span> <span class="title class_">Page</span>&lt;&gt;(current, pageSize), <span class="built_in">this</span>.getQueryWrapper(queryRequest));</span><br><span class="line">    Page&lt;PictureVO&gt; pictureVOPage = <span class="built_in">this</span>.getPictureVOPage(picturePage);</span><br><span class="line">    <span class="comment">// 4. 写入数据到 Redis</span></span><br><span class="line">    <span class="comment">// 设置过期时间(添加随机时间, 防止缓存雪崩)</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">timeout</span> <span class="operator">=</span> <span class="number">300</span> + RandomUtil.randomInt(<span class="number">0</span>, <span class="number">300</span>);</span><br><span class="line">    redisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(pictureVOPage), timeout, TimeUnit.SECONDS);</span><br><span class="line">    <span class="keyword">return</span> pictureVOPage;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="缓存永不过期"><a href="#缓存永不过期" class="headerlink" title="缓存永不过期"></a>缓存永不过期</h3><p>该方案就是针对于几乎不会改变的数据不设置过期时间，在有需要修改的场景进行异步删除或更新即可。</p><h3 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h3><p>利用定时任务提前对缓存做预热，保证用户直接查询缓存而不是数据库。</p><h3 id="多级缓存"><a href="#多级缓存" class="headerlink" title="多级缓存"></a>多级缓存</h3><p>结合本地缓存与分布式缓存一起使用，并设置不同的过期时间，避免对数据库直接造成请求。比如本地缓存 Caffeine 结合分布式缓存 Redis 共同构成多级缓存，避免缓存雪崩。</p><p>下面是一个我之前项目中使用的一个多级缓存示例。</p><img  src=http://www.plantuml.com/plantuml/svg/ZP7BJW8n58RtVOecB9GToY3Y68tYqfNw0hNjI0DEIMVK6ED2ZSRx3JL6lCVRGW4Jl8k-3Etm68uC6X0JtJJfVyv_llFdDC1IviqfPDHslbX8gUC7-Re6h3WpaqYWOMZ54E5Zp1o21afO5806A3DxnQS5TJVbN2t9sHadVrpdGjXceymUXnEW6-7uaE0Z9edo11VjxRqSeqGKuHZjw80-h15i6FLTVPGmwy-k7cIZGMJLz711g2ZNeI-e1P4M0Fqs4dP5QegqXaEQA_5aHI4u6D92e4i8FbQH0gI56WJqCfCEn1YEczIoO3EOh8f_S59ykQyBpepwoD178nJJ7wkru70eJ42VroPCAc1Ju9DWCpj1eJpRSvuldTUKlDbL-HUvU2NJRm1Odqb0crezLrltfUo3kftMtU_HUIbxglQlvNxEiy0eCWpghgy3TwL6jPkLwnToer1ylEdqGpj6pRBe1ssbzosPFgpsgksSMideBeid0NMF3XjTi_yB8-VdvEEC6xj2Ab_gJunAvzLEhXgZVx6z2V1VSAyidrFwRoFbvdBDi6_4jwrsl4cOuRqV><p>1、引入依赖 (JDK11+)</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Caffeine --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.github.ben-manes.caffeine<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>caffeine<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2、Caffeine 缓存工具类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Caffeine 缓存工具类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CaffeineUtil</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Cache&lt;String, String&gt; LOCAL_CACHE = Caffeine.newBuilder()</span><br><span class="line">    .initialCapacity(<span class="number">1024</span>) <span class="comment">// 初始容量</span></span><br><span class="line">    .maximumSize(<span class="number">10000L</span>) <span class="comment">// 最大容量</span></span><br><span class="line">    .expireAfterWrite(<span class="number">5L</span>, TimeUnit.MINUTES) <span class="comment">// 5 分钟过期</span></span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Cache&lt;String, String&gt; <span class="title function_">getCache</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> LOCAL_CACHE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3、构建多级缓存示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Redis + Caffeine 多级缓存</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> queryRequest 查询参数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 分页结果</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> Page&lt;PictureVO&gt; <span class="title function_">listPictureVOByPageWithCache</span><span class="params">(PictureQueryRequest queryRequest)</span> &#123;</span><br><span class="line">    <span class="comment">// 1. 构建 Key</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">jsonStr</span> <span class="operator">=</span> JSONUtil.toJsonStr(queryRequest);</span><br><span class="line">    <span class="type">String</span> <span class="variable">md5Str</span> <span class="operator">=</span> DigestUtils.md5DigestAsHex(jsonStr.getBytes());</span><br><span class="line">    <span class="keyword">final</span> <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> <span class="string">&quot;picture:listPictureVOByPage:&quot;</span> + md5Str;</span><br><span class="line">    <span class="comment">// 2. 先查询 Caffeine</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">valueData</span> <span class="operator">=</span> CaffeineUtil.getCache().getIfPresent(key);</span><br><span class="line">    <span class="keyword">if</span> (StrUtil.isNotBlank(valueData)) &#123;</span><br><span class="line">        <span class="comment">// 存在, 直接返回</span></span><br><span class="line">        <span class="keyword">return</span> JSONUtil.toBean(valueData, <span class="keyword">new</span> <span class="title class_">TypeReference</span>&lt;Page&lt;PictureVO&gt;&gt;() &#123;</span><br><span class="line">        &#125;, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 3. 不存在, 查询 Redis</span></span><br><span class="line">    valueData = redisTemplate.opsForValue().get(key);</span><br><span class="line">    <span class="keyword">if</span> (StrUtil.isNotBlank(valueData)) &#123;</span><br><span class="line">        <span class="comment">// redis 中存在, 先更新本地缓存, 再返回结果</span></span><br><span class="line">        CaffeineUtil.getCache().put(key, valueData);</span><br><span class="line">        <span class="keyword">return</span> JSONUtil.toBean(valueData, <span class="keyword">new</span> <span class="title class_">TypeReference</span>&lt;Page&lt;PictureVO&gt;&gt;() &#123;</span><br><span class="line">        &#125;, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 4. 都不存在, 查询数据库</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">current</span> <span class="operator">=</span> queryRequest.getCurrent();</span><br><span class="line">    <span class="type">int</span> <span class="variable">pageSize</span> <span class="operator">=</span> queryRequest.getPageSize();</span><br><span class="line">    Page&lt;Picture&gt; picturePage = <span class="built_in">this</span>.page(<span class="keyword">new</span> <span class="title class_">Page</span>&lt;&gt;(current, pageSize), <span class="built_in">this</span>.getQueryWrapper(queryRequest));</span><br><span class="line">    Page&lt;PictureVO&gt; pictureVOPage = <span class="built_in">this</span>.getPictureVOPage(picturePage);</span><br><span class="line">    <span class="comment">// 5. 写入数据到 Caffeine</span></span><br><span class="line">    CaffeineUtil.getCache().put(key, JSONUtil.toJsonStr(pictureVOPage));</span><br><span class="line">    <span class="comment">// 6. 写入数据到 Redis</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">timeout</span> <span class="operator">=</span> <span class="number">300</span> + RandomUtil.randomInt(<span class="number">0</span>, <span class="number">300</span>);</span><br><span class="line">    redisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(pictureVOPage), timeout, TimeUnit.SECONDS);</span><br><span class="line">    <span class="keyword">return</span> pictureVOPage;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="不可避免的缓存雪崩突发情况"><a href="#不可避免的缓存雪崩突发情况" class="headerlink" title="不可避免的缓存雪崩突发情况"></a>不可避免的缓存雪崩突发情况</h2><p>针对于 Redis 突然宕机，或者内存不够导致淘汰其他缓存数据，或者机房被洪水淹了等不可抗力因素导致的缓存雪崩问题，我们有如下的对应方案：</p><p>1、做好 Redis 的高可用，要么搭建主从 + 哨兵节点要么搭建多主多从集群。</p><p>2、做好服务的降级限流熔断的服务保护措施，做好兜底。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式锁介绍及基本原理</title>
      <link href="/2025/08/23/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/"/>
      <url>/2025/08/23/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="锁与分布式锁"><a href="#锁与分布式锁" class="headerlink" title="锁与分布式锁"></a>锁与分布式锁</h1><p>在多线程环境中，如果多个线程同时访问共享资源 (例如商品库存、外卖订单)，会发生数据竞争，可能会导致出现脏数据或者系统问题，威胁到程序的正常运行。</p><p>举个例子，假设现在有 100 个用户参与某个限时秒杀活动，每位用户限购 1 件商品，且商品的数量只有 3 个。如果不对共享资源进行互斥访问，就可能出现以下情况：</p><ul><li>线程 1、2、3 等多个线程同时进入抢购方法，每一个线程对应一个用户。</li><li>线程 1 查询用户已经抢购的数量，发现当前用户尚未抢购且商品库存还有 1 个，因此认为可以继续执行抢购流程。</li><li>线程 2 也执行查询用户已经抢购的数量，发现当前用户尚未抢购且商品库存还有 1 个，因此认为可以继续执行抢购流程。</li><li>线程 1 继续执行，将库存数量减少 1 个，然后返回成功。</li><li>线程 2 继续执行，将库存数量减少 1 个，然后返回成功。</li><li>此时就发生了超卖问题，导致商品被多卖了一份。</li></ul><h2 id="锁的出现"><a href="#锁的出现" class="headerlink" title="锁的出现"></a>锁的出现</h2><p>为了保证共享资源被安全地访问，我们需要使用互斥操作对共享资源进行保护，<strong>即同一时刻只允许一个线程访问共享资源</strong>，其他线程需要等待当前线程释放后才能访问。这样可以避免数据竞争和脏数据问题，保证程序的正确性和稳定性。</p><p>在计算机领域，锁可以理解为针对某项资源使用权限的管理，它通常用来 <strong>控制共享资源</strong>，比如一个进程内有多个线程竞争一个数据的使用权限，解决方式之一就是加锁，更确切的说则是 “悲观锁”。</p><p>悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题 (比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会被阻塞，直到锁被上一个持有者释放。也就是说，<strong>共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程</strong>。</p><p>对于单体应用来说，在 Java 中，我们通常会使用 <code>ReentrantLock</code> 类、<code>synchronized</code> 关键字这类 JDK 本身就拥有的方式来控制一个 JVM 进程内的多个线程对共享资源的访问。<br><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250822182730857.png" alt="image-20250822182442644" /><br>从图中可以看出，这些线程访问共享资源是互斥的，<strong>同一时刻只有一个线程可以获取到本地锁访问共享资源</strong>。</p><h2 id="分布式锁的出现"><a href="#分布式锁的出现" class="headerlink" title="分布式锁的出现"></a>分布式锁的出现</h2><p>分布式系统下，不同的服务&#x2F;客户端通常运行在独立的 JVM 进程上。如果多个 JVM 进程共享同一份资源的话，使用本地锁就没办法实现资源的互斥访问了。于是，<strong>分布式锁</strong> 就诞生了。</p><p>举个例子：系统的订单服务一共部署了 3 份，都对外提供服务。用户下订单之前需要检查库存，为了防止超卖，这里需要加锁以实现对检查库存操作的同步访问。由于订单服务位于 <strong>不同的 JVM 进程</strong> 中，本地锁在这种情况下就没办法正常工作了。我们需要用到分布式锁，这样的话，即使多个线程不在同一个 JVM 进程中也能获取到同一把锁，进而实现共享资源的互斥访问。<br><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250822183716898.png" alt="image-20250822183716824" /><br>从图中可以看出，这些独立的进程中的线程访问共享资源是互斥的，<strong>同一时刻只有一个线程可以获取到分布式锁访问共享资源</strong>。</p><h1 id="分布式锁设计注意事项"><a href="#分布式锁设计注意事项" class="headerlink" title="分布式锁设计注意事项"></a>分布式锁设计注意事项</h1><h2 id="设计分布式锁需要具备哪些条件？"><a href="#设计分布式锁需要具备哪些条件？" class="headerlink" title="设计分布式锁需要具备哪些条件？"></a>设计分布式锁需要具备哪些条件？</h2><p>1、<strong>互斥</strong>：同一时刻保证只有一个线程能够获得锁，去访问共享资源。</p><p>2、<strong>高可用</strong>：要保证即使出现异常的情况也要对锁进行释放，确保不会影响其他线程对共享资源的访问。</p><p>3、<strong>可重入</strong>：一个节点获取了锁之后，还可以再次获取到锁，并且不止一次。</p><p>4、<strong>高性能</strong>：获取和释放锁的操作应该快速完成，并且尽量不要对整个系统的性能造成太大的影响。</p><p>5、<strong>对称性</strong>：确保加锁和解锁的是同一个线程，避免出现锁的 “误释放”。</p><h2 id="分布式锁有哪些实现方案？"><a href="#分布式锁有哪些实现方案？" class="headerlink" title="分布式锁有哪些实现方案？"></a>分布式锁有哪些实现方案？</h2><p>主流的分布式锁实现方案主要有 3 种：</p><ul><li>基于关系型数据库 MySQL 实现分布式锁</li><li>基于分布式存储系统 Redis 或 Etcd 实现分布式锁</li><li>基于分布式协调服务 ZooKeeper 实现分布式锁</li></ul><p>鉴于种种原因，实际在生产过程中使用 Redis 或 ZooKeeper 实现分布式锁居多。</p><h1 id="分布式锁实现"><a href="#分布式锁实现" class="headerlink" title="分布式锁实现"></a>分布式锁实现</h1><h2 id="基于-Redis-循序渐进实现分布式锁"><a href="#基于-Redis-循序渐进实现分布式锁" class="headerlink" title="基于 Redis 循序渐进实现分布式锁"></a>基于 Redis 循序渐进实现分布式锁</h2><h3 id="最简单的分布式锁"><a href="#最简单的分布式锁" class="headerlink" title="最简单的分布式锁"></a>最简单的分布式锁</h3><p>要实现一个分布式锁，得满足锁的基本特性：即一个线程拿到锁，另一个线程就拿不到，就不能往下走，这就是锁的互斥性。</p><p>在 Redis 当中，提供了一个 <code>SETNX</code> 的命令来帮助我们实现一个简单的分布式锁。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETNX key value</span><br></pre></td></tr></table></figure><p>Redis 官方对于该命令的解释是：<code>Set the string value of a key only when the key doesn&#39;t exist</code> 只有当 key 不存在的时候，才会设置 key 的值 (加锁)。这样就可以帮助我们天然的实现分布式场景下的互斥性。</p><p>但是为了保证对称性，在解锁的时候我们则需要先判断这个锁是否是当前线程加的锁，从而避免释放掉别人的锁。此时就包括两个步骤：判断、释放锁。但是为了避免多线程环境下的并发安全问题，我们则需要使用 Lua 脚本来保证这两条命令的原子性。</p><p>释放锁的 Lua 脚本示例：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 释放锁时, 先比较锁对应的 value 值是否相等, 避免锁的误释放</span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>至于为什么不把 <code>SETNX</code> 命令放到 Lua 脚本当中，这是因为 Redis 执行操作命令是单线程执行的，天然就是原子性操作。</p><p>这是实现分布式锁的最简易版本，会存在大量的问题。比如：<strong>如果一个线程拿到锁之后就挂了，此时就无法释放锁了，该怎么办？</strong></p><h3 id="带有过期时间的分布式锁"><a href="#带有过期时间的分布式锁" class="headerlink" title="带有过期时间的分布式锁"></a>带有过期时间的分布式锁</h3><p>为了解决上述出现的问题，我们就需要给这个锁设置一个过期时间。Redis 当中也存在了设置过期时间对应的 <code>SET</code> 命令。</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET key value [NX|XX] [GET] [EX seconds|PX milliseconds|EXAT unix-time-seconds|PXAT unix-time-milliseconds|KEEPTTL]</span><br></pre></td></tr></table></figure><p>具体解释每一个命令如下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1.</span> SET key value: 设置 key 与 value</span><br><span class="line"><span class="bullet">2.</span> []: 代表可选操作</span><br><span class="line"><span class="bullet">3.</span> NX|XX: 二选一属性</span><br><span class="line"><span class="bullet">   -</span> NX(Not Exists): 只有当 key 不存在的时候才会设置 key 的值, 相当于上面的 <span class="code">`SETNX`</span> 命令</span><br><span class="line"><span class="bullet">   -</span> XX(Exists): 只有当 key 存在的时候才会设置 key 的值, 不存在则忽略该操作</span><br><span class="line"><span class="bullet">4.</span> GET: 执行 <span class="code">`SET`</span> 操作的同时返回原来的旧值, 如果 key 不存在, 返回 nil</span><br><span class="line"><span class="bullet">   -</span> 示例: </span><br><span class="line"><span class="bullet">       1.</span> 执行: SET name &quot;Alice&quot;</span><br><span class="line"><span class="bullet">       2.</span> 返回: OK</span><br><span class="line"><span class="bullet">       3.</span> 执行: SET name &quot;Bob&quot; GET</span><br><span class="line"><span class="bullet">       4.</span> 返回: &quot;Alice&quot;</span><br><span class="line"><span class="bullet">5.</span> 过期时间参数, 只能选一个</span><br><span class="line"><span class="bullet">   -</span> EX seconds: 设置过期时间为 xx 秒(整数)</span><br><span class="line"><span class="bullet">   -</span> PX milliseconds: 设置过期时间为 xx 毫秒(整数)</span><br><span class="line"><span class="bullet">   -</span> EXAT unix-time-seconds: 设置过期的 Unix 时间戳(秒级), 到指定时间后过期</span><br><span class="line"><span class="bullet">   -</span> PXAT unix-time-milliseconds: 设置过期的 Unix 时间戳(毫秒级), 到指定时间后过期</span><br><span class="line"><span class="bullet">   -</span> KEEPTTL: 保留 key 原有的过期时间(如果 key 已存在且有过期时间, 则不改变其过期时间; 如果 key 不存在, 则设置为永久)</span><br></pre></td></tr></table></figure><p>针对于 <code>SET</code> 命令实现可过期的分布式锁，具体的命令示例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数的顺序不会影响命令</span></span><br><span class="line">SET lockKey uniqueValue EX 3 NX 或 SET lockKey uniqueValue NX EX 3 <span class="comment"># 3s 后过期</span></span><br></pre></td></tr></table></figure><p>这种方式实现的分布式锁还是会存在问题：<strong>假设线程拿到锁后任务还没有执行完成，锁就已经过期了，这个时候该怎么办？</strong></p><h3 id="锁的优雅续期"><a href="#锁的优雅续期" class="headerlink" title="锁的优雅续期"></a>锁的优雅续期</h3><p>此时我们应该想：如果能够自动判断锁的过期时间，在业务还没执行完的时候进行锁的自动续期，这该多是一件美事！！！</p><p>针对于这种情况，Java 已经有了现成的解决方案：<strong>Redisson</strong>。Redisson 是一个基于 Redis 的 Java 高级客户端，底层基于 Netty 实现。Redisson 提供了如分布式锁、分布式限流、分布式集合等高级特性。</p><p>Redisson 中的分布式锁自带自动续期机制，使用起来非常简单。其提供了一个专门用来监控和续期锁的 <strong>Watch Dog（ 看门狗）</strong>，如果操作共享资源的线程还未执行完成的话，Watch Dog 会不断地延长锁的过期时间，进而保证锁不会因为超时而被释放。<br><img src="https://picgo-blog-1335849645.cos.ap-guangzhou.myqcloud.com/images/20250822195810641.png" alt="image-20250822195810515" /><br>关于 Watch Dog 看门狗机制，这里不做过多阐述，后续会单独写一篇文章进行详细说明。</p><p>通过续期方式实现的分布式锁还是会存在一定的问题：<strong>假设线程拿到锁在执行业务方法的时候挂了，这时候  Watch Dog 就会不断地给锁进行续期，该怎么解决？有些场景还需要使用到可重入的分布式锁，又该怎么解决？</strong></p><h3 id="可重入的分布式锁"><a href="#可重入的分布式锁" class="headerlink" title="可重入的分布式锁"></a>可重入的分布式锁</h3><p>针对于上述第一个问题，我们可以这样操作：</p><ul><li>把看门狗线程设置为守护线程，守护线程的生命周期依赖于其他线程，一旦拿到锁的线程在执行业务的时候挂了，那么看门狗作为守护线程也是会停止的。</li><li>我们也需要给看门狗设置一个时间 (默认30s 续期一次)，避免无限续期。</li></ul><p>下面来讨论可重入分布式锁的实现。</p><p>可重入锁指的是 <strong>在一个线程中可以多次获取同一把锁</strong>。比如一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程就需要多次来获取同一个锁，这就是可重入锁。</p><p>Java 中的 <code>synchronized</code> 和 <code>ReentrantLock</code> 都属于可重入锁。</p><p>那我们该怎么实现一个可重入锁呢？在解答这个问题之前，需要先看看 <code>synchronized</code> 和 <code>ReentrantLock</code> 是怎么实现可重入的。</p><p>synchronized 给每个对象都关联了一个锁监视器，监视器中有个字段是锁计数器。锁重入一次，计数器加一次，锁释放一次，计数器减一次，当计数器为 0 的时候，就是锁释放完毕的时候。</p><p>ReentrantLock 基于 AQS 进行实现。AQS 中存在一个 state 字段，state 字段就充当了锁计数器，锁重入一次，state 加一次，锁释放一次，state 减一次，当 state 为 0 的时候，就是锁释放完毕的时候。</p><p>那么对于可重入的分布式锁，实际项目中，我们不需要自己手动实现，推荐使用我们上面提到的 <strong>Redisson</strong> ，其内置了多种类型的锁。比如可重入锁 (Reentrant Lock)、自旋锁 (Spin Lock)、公平锁 (Fair Lock)、多重锁 (MultiLock)、 红锁 (RedLock)、 读写锁 (ReadWriteLock)。</p><p>而如果让我们自行实现可重入的分布式锁，则也需要根据锁计数器来实现，主要的实现方案有以下两种。</p><h4 id="第一种方案"><a href="#第一种方案" class="headerlink" title="第一种方案"></a>第一种方案</h4><p>使用 Redis 的哈希结构，以要锁的东西为 key，以当前的线程 Id 为 field，以重入次数为 value，这个 value 充当的角色就是锁计数器。</p><p>当然，这种方案也是 Redisson 可重入锁的实现方案，使用的是 <code>HSETNX</code> 命令。</p><p>但是由于集群环境下可能会出现线程 Id 重复的现象，我们最好是使用当前的线程 Id 再拼接一个 UUID 来保证唯一性。</p><h4 id="第二种方案"><a href="#第二种方案" class="headerlink" title="第二种方案"></a>第二种方案</h4><p>不使用 Redisson 提供好的可重入分布式锁，还是使用 Redis 中的 String 结构的 <code>SET NX EX</code> 命令来实现分布式锁，但是在服务内部维护一个 <code>ConcurrentHashMap</code> ，以 map 的 value 作为锁计数器，来实现锁的可重入性。</p><h3 id="Redisson-中的发布订阅"><a href="#Redisson-中的发布订阅" class="headerlink" title="Redisson 中的发布订阅"></a>Redisson 中的发布订阅</h3><p><strong>如果一个线程抢到锁去执行业务去了，那么其他没抢到锁的线程就直接返回失败吗？</strong></p><p>当然不是。没抢到锁的线程不会直接返回失败信息，可以进行重试机制。分布式锁也可以通过不断自旋来尝试重新抢锁，但是 Redisson 底层不是这么实现的。</p><p>Redisson 基于 Redis 的发布订阅机制，让没有抢到锁的线程进行订阅，然后阻塞等待。</p><p>抢到锁的线程执行完任务后会发布一条消息来通知订阅的所有线程，唤醒它们进行重新抢锁。</p><p>没抢到锁的线程继续订阅，抢到锁的线程继续执行业务，执行完业务后继续发布消息，如此循环往复。不过需要注意的是要添加一个超时时间来进行控制，避免抢不到锁的线程无限等待下去。</p><h3 id="Redis-集群环境下的锁丢失问题"><a href="#Redis-集群环境下的锁丢失问题" class="headerlink" title="Redis 集群环境下的锁丢失问题"></a>Redis 集群环境下的锁丢失问题</h3><p>如果 Redis 是一主多从的集群模式，当执行分布式锁的 Redis 命令写入到主节点后，主节点正在或是即将同步数据给从节点的某一刻，Redis 的主节点突然宕机了，那么就会触发 Redis 的重新选主操作，选择某一个从节点转化为主节点。</p><p>但是新的主节点是没有分布式锁的数据的，那么其他线程还是能够加锁成功的，由于开始的主节点宕机没有及时同步数据到从节点，这就造成了第一次加的锁造成了丢失，这又该如何应对？</p><h4 id="Redisson-的联锁-MultiLock"><a href="#Redisson-的联锁-MultiLock" class="headerlink" title="Redisson 的联锁 (MultiLock)"></a>Redisson 的联锁 (MultiLock)</h4><p>针对于以上锁丢失问题，Redisson 提供了 <strong>联锁</strong> 机制来解决。联锁要求 Redis 部署多主多从的集群环境。</p><p>每次加锁都必须给所有主节点都加上锁才算加锁成功。</p><p>这样即便某个主节点还没来得及同步数据就宕机，那么其他几个主节点也是有锁的数据的，新线程再想加锁, 由于无法给所有主节点都加锁，还是会加锁失败的。这样就解决了一主多从模式下锁丢失的问题。</p><p><strong>但是真的完美了吗？</strong></p><p><strong>在给所有主节点加锁的过程中，如果某个主节点网络延迟很大，加锁很慢，或者说某个主节点宕机了，一直加锁失败，由于联锁的机制，那就会导致整体加锁失败。</strong></p><p><strong>此时我们又该如何应对？</strong></p><h4 id="Redisson-的红锁-RedLock"><a href="#Redisson-的红锁-RedLock" class="headerlink" title="Redisson 的红锁 (RedLock)"></a>Redisson 的红锁 (RedLock)</h4><p>此时就需要请出 Redisson 的又一个锁机制了：<strong>RedLock 红锁</strong>。RedLock 也要求 Redis 部署多主多从的集群环境，但是加锁的时候不需要全部的主节点都加锁成功，而是只需要 <strong>半数以上的主节点加锁成功即可</strong> 。</p><p>当某个线程加锁半数以上节点都成功了，那其他线程就不可能再做到半数以上加锁成功，这就满足了互斥性。</p><p>同时 RedLock 对加锁时间也有很严格的要求，如果某个节点一定时间内加不上锁就不等了，反正只要半数以上成功就行，放弃一两个比较慢的主节点是无所谓的。</p><p><strong>但是但是但是，到这里就万无一失了吗？</strong></p><p>显然并不是，RedLock 还存在一些其他的问题：</p><ul><li>RedLock 对时间要求很严格，但是不同节点的系统时钟也可能不一致，从而导致问题。</li><li>Java 的 GC 过程中是会暂停线程的，从而导致看门狗线程无法对锁进行续期，也可能导致锁的超时过期。</li><li>RedLock 自身也存在一定的问题，且需要搭建复杂的多主多从集群模式，维护起来非常困难，还要保证多个节点之间的数据一致性，因此 RedLock 的使用场景并不广泛。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>综上所述，实现分布式锁的最佳实践有两种方式：</p><ul><li>基于 Redis 的 <code>SET NX EX</code> 实现简单的不可重入的分布式锁。</li><li>直接使用 Redisson 提供好的分布式锁机制。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式锁 </tag>
            
            <tag> Redis </tag>
            
            <tag> Redisson </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
